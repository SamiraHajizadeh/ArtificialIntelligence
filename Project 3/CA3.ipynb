{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad64795c",
   "metadata": {},
   "source": [
    "# Artificial Intelligence - CA 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d1888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in d:\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in d:\\anaconda3\\lib\\site-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from nltk==3.3->hazm) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing needed libraries\n",
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e3841ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting parsivar"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: hazm 0.7.0 has requirement nltk==3.3, but you'll have nltk 3.4.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading parsivar-0.2.3.tar.gz (36.2 MB)\n",
      "Collecting nltk==3.4.5\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from nltk==3.4.5->parsivar) (1.15.0)\n",
      "Building wheels for collected packages: parsivar, nltk\n",
      "  Building wheel for parsivar (setup.py): started\n",
      "  Building wheel for parsivar (setup.py): finished with status 'done'\n",
      "  Created wheel for parsivar: filename=parsivar-0.2.3-py3-none-any.whl size=36492963 sha256=f11b32cab5018878c762c4580fa8699448582d1c90e1a981ced12a55273ee3e3\n",
      "  Stored in directory: c:\\users\\pr\\appdata\\local\\pip\\cache\\wheels\\54\\0a\\38\\7d0b1aabbd644340a94fb8685fd20d9f35814d735973d07f40\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449911 sha256=dfca92b38f3135b793d8c8bacc5e5c0f533e4a73f987b8f0d5566010c7ad1739\n",
      "  Stored in directory: c:\\users\\pr\\appdata\\local\\pip\\cache\\wheels\\23\\18\\48\\8fd6ec11da38406b309470566d6f099c04805d2ec61d7829e7\n",
      "Successfully built parsivar nltk\n",
      "Installing collected packages: nltk, parsivar\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.3\n",
      "    Uninstalling nltk-3.3:\n",
      "      Successfully uninstalled nltk-3.3\n",
      "Successfully installed nltk-3.4.5 parsivar-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install parsivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "31b238c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "import os\n",
    "import pandas as pd\n",
    "import hazm\n",
    "from collections import Counter\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from hazm.utils import stopwords_list\n",
    "import parsivar\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a59dff",
   "metadata": {},
   "source": [
    "### PART 1 - Preprocessing\n",
    "\n",
    "The following steps were taken for preprocessing our data:\n",
    "\n",
    "    1.Normalizing \n",
    "    2.Stemming\n",
    "    3.Lemmatizing\n",
    "    4.Removing stopwords\n",
    "    5.Removing punctutations and useless characters\n",
    "    \n",
    "\n",
    "Stemming and Lemmatizing on average lowered the accuracy of our model. This is probably due to the fact that the normalizer functions were unsuccessful in stripping 'u\\200c' from the passed strings. In the end, the only functions used were removing stop words and punctuations. \n",
    "The stop words used were a combination of imported stopwords (from Hazm) and the most common words in in the data.\n",
    "\n",
    "***In order to preprocess our data we use Hazm library. \n",
    "\n",
    "\n",
    "##### Stemming\n",
    "\n",
    "Stemming is a technique where a set of words in a sentence are converted into a sequence to shorten its lookup. The words which have the same meaning but have some variation according to the context or sentence are normalized.\n",
    "\n",
    "##### Lemmatization\n",
    "\n",
    "Lemmatization is the algorithmic process of finding the lemma (dictionary form) of a word depending on their meaning. Lemmatization usually refers to the morphological analysis of words, which aims to remove inflectional endings. It helps in returning the base or dictionary form of a word, which is known as the lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c88a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our data\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "train_text = open('train.csv', encoding='utf8').read()\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_text = open('test.csv', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "67555b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    \n",
    "    s = ''\n",
    "    words = []\n",
    "    \n",
    "    for i in text:\n",
    "        if i.isalpha():\n",
    "            s += i.upper()\n",
    "        elif s != '':\n",
    "            words.append(s)\n",
    "            s = ''\n",
    "    if s != '':\n",
    "        words.append(s)\n",
    "            \n",
    "    return words\n",
    "\n",
    "\n",
    "normalizer = hazm.Normalizer()\n",
    "stemmer = hazm.Stemmer()\n",
    "lemmatizer = hazm.Lemmatizer()\n",
    "find_stems = parsivar.FindStems()\n",
    "\n",
    "def stop_word_list(file_name, number):\n",
    "\n",
    "    content = open(file_name, encoding='utf8').read()\n",
    "    data = Counter(get_words(content))\n",
    "    common_words = data.most_common(number)\n",
    "    \n",
    "    for i in range(number):\n",
    "        common_words[i] = common_words[i][0]\n",
    "        \n",
    "    return common_words\n",
    "\n",
    "\n",
    "def norm_stem_lem(string):\n",
    "    \n",
    "    string = normalizer.normalize(string)\n",
    "    string = normalizer.affix_spacing(string)\n",
    "    words = get_words(string)\n",
    "    \n",
    "    #for i in range(len(words)):\n",
    "    #    stemmer.stem(words[i])\n",
    "    #    words[i] = lemmatizer.lemmatize(words[i])\n",
    "    #    words[i] = stemmer.stem(words[i])\n",
    "        \n",
    "    return words\n",
    "\n",
    "\n",
    "def remove_stop_words(words, processed_stop_words, to_string=False):\n",
    "    \n",
    "    filtered_words = [word for word in words if word not in [''] + processed_stop_words]\n",
    "    if to_string:\n",
    "        return ' '.join(e for e in filtered_words)\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "def preprocess(file_name, number):\n",
    "    \n",
    "    stop_words_imported = stopwords_list() #stop_word_list(file_name, number)\n",
    "    stop_words_text = stop_word_list(file_name, number)\n",
    "    stop_words = stop_words_imported + stop_words_text + ['ی', 'یا', 'ای']\n",
    "    \n",
    "    csv_reader = csv.reader(open(file_name,'r', encoding='utf8'))\n",
    "    #preprocessed_stop_words = norm_stem_lem(' '.join(w for w in stop_words))\n",
    "    \n",
    "    csv_text = []\n",
    "    \n",
    "    for row in csv_reader:\n",
    "        \n",
    "        label = norm_stem_lem(row[1])\n",
    "        label = remove_stop_words(label, stop_words, to_string=True)\n",
    "        content = norm_stem_lem(row[0])\n",
    "        content = remove_stop_words(content, stop_words)\n",
    "        csv_text.append([label, content])\n",
    "            \n",
    "    return csv_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f800892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_text = preprocess('train.csv', 13)[1:]\n",
    "preprocessed_test_text = preprocess('test.csv', 13)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355052f3",
   "metadata": {},
   "source": [
    "### PART 2 - Problem's Process\n",
    "\n",
    "\n",
    "In this problem, we have the prior probability (that given a certain label, what is the possibility of having a word.) Now with using this information and two other terms we want to predict the label of the content with the words seen in it.\n",
    "\n",
    "This is done with the help of bayas theorm, in which the likelihood (the probability of seeing a word given a label) is multiplied by prior (the probability of seeing a label) and divided by the evidence (the probability of seeing the word.)\n",
    "The output of this is the posterior or the probability of having a certain label given that a certain word is presented in it.\n",
    "\n",
    "To sum up we have:\n",
    "\n",
    "    P(c|x) is the posterior probability of class (c, target) given predictor (x, attributes).\n",
    "    P(c) is the prior probability of class.\n",
    "    P(x|c) is the likelihood which is the probability of predictor given class.\n",
    "    P(x) is the prior probability of predictor.\n",
    "\n",
    "where c is the label and x is the content seen and each term is calculated as follows:\n",
    "\n",
    "    P(c|x): is calculated using the bayas theorm\n",
    "    P(c): times a label is seen / the number of all labels\n",
    "    P(x|c): times a word is seen given a label\n",
    "    P(x): times a word is seen / the number of all the words available (counting the repeated ones as well.)\n",
    "    \n",
    "    \n",
    "#### Bigrams\n",
    "\n",
    "\n",
    "For instance in these two sentences: 'I have a broken watch' and 'There was a fight during the night watch' the word 'watch' has two totally different meanings which can be determined by using bigrams. In other words, by attaching 'broken' and 'night' to watch the meanings will become totally clear. \n",
    "\n",
    "In this example, using the bigrams suffices, but there are many examples in which only the use of three or more words alongside each other can clarify the meaning of the sentence. In order to cover these examples as well, we use N-grams in natural language processing.\n",
    "    \n",
    "    \n",
    "#### Additive smoothing\n",
    "\n",
    "    The problem: if a word is seen only in one category while training, the P(X|C) term of bayas theorm will be equal to 0. As a result, the output probability or P(C|X) will be 0 as well.\n",
    "\n",
    "    Solution: Additive Smoothing\n",
    "    \n",
    "In statistics, additive smoothing, also called Laplace smoothing is a technique used to smooth categorical data. Given a set of observation counts ${\\textstyle \\textstyle {\\mathbf {x} \\ =\\ \\left\\langle x_{1},\\,x_{2},\\,\\ldots ,\\,x_{d}\\right\\rangle }}$ from a ${\\textstyle \\textstyle {d}}$-dimensional multinomial distribution with ${\\textstyle \\textstyle {N}}$ trials, a \"smoothed\" version of the counts gives the estimator:\n",
    "\n",
    "${\\displaystyle {\\hat {\\theta }}_{i}={\\frac {x_{i}+\\alpha }{N+\\alpha d}}\\qquad (i=1,\\ldots ,d)}$,\n",
    "\n",
    "where the smoothed count ${\\textstyle \\textstyle {{\\hat {x}}_{i}=N{\\hat {\\theta }}_{i}}}$ and the \"pseudocount\" α > 0 is a smoothing parameter. α = 0 corresponds to no smoothing.\n",
    "Additive smoothing is a type of shrinkage estimator, as the resulting estimate will be between the empirical probability (relative frequency)  $ {\\textstyle \\textstyle {x_{i}/N}}$, and the uniform probability ${\\textstyle \\textstyle {1/d}}$. \n",
    "\n",
    "\n",
    "From a Bayesian point of view, this corresponds to the expected value of the posterior distribution, using a symmetric Dirichlet distribution with parameter α as a prior distribution. \n",
    "\n",
    "\n",
    "In order to implement this in our code, we replace P(X|C) with (P(X and C) + 1) / (N + k), where:\n",
    "\n",
    "    K represents the dimensions(no of features) in the data,\n",
    "    N represents the number of reviews with target_outcome=positive ==> N = P(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7aee74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(csv_text):\n",
    "    \n",
    "    labels = {}\n",
    "    \n",
    "    for i in range(len(csv_text)):\n",
    "        if csv_text[i][0] not in labels:\n",
    "            labels[csv_text[i][0]] = 0\n",
    "            \n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_labels_of_words(train_data, labels):\n",
    "    \n",
    "    word_dict = {}\n",
    "    word_no = 0\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        \n",
    "        label, content = train_data[i]\n",
    "        \n",
    "        for word in content:\n",
    "            word_no += 1\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = [0, 0, 0, 0]\n",
    "                \n",
    "            index = labels.index(label)\n",
    "            word_dict[word][index] += 1\n",
    "            \n",
    "    return word_dict, word_no\n",
    "\n",
    "\n",
    "\n",
    "def get_label_pr_for_word(train_data, word, words_no, word_dict, labels_dict, pr_label, pr_total_dict):\n",
    "    \n",
    "    if word not in word_dict:\n",
    "    #    return pr_total_dict\n",
    "        word_number = 0\n",
    "    else:\n",
    "        word_number = sum(word_dict[word])\n",
    "        \n",
    "    K = len(list(word_dict.keys()))\n",
    "\n",
    "    for label in labels:\n",
    "        \n",
    "        #num_c_and_x = word_dict[word][list(labels.keys()).index(label)]\n",
    "        #pr_c = pr_label[label]\n",
    "        #num_x = word_number\n",
    "        #num_c = pr_label[label] * words_no\n",
    "        #K = len(list(word_dict.keys()))\n",
    "        \n",
    "        #pr_total_dict[label] += (num_c_and_x+1) / (num_c + K)  * pr_c\n",
    "        \n",
    "        if word not in word_dict:\n",
    "            pr_total_dict[label] += 1 / (pr_label[label] * words_no + K) / words_no * pr_label[label]\n",
    "        else:\n",
    "            pr_total_dict[label] += (word_dict[word][list(labels.keys()).index(label)] + 1) / (pr_label[label] * words_no + K) * pr_label[label]\n",
    "        \n",
    "        # pr_total_dict[label] += word_dict[word][list(labels.keys()).index(label)] / pr_label[label] / word_number * pr_label[label]\n",
    "        # pr_total_dict[label] += word_dict[word][list(labels.keys()).index(label)] * pr_label[label] / word_number\n",
    "        \n",
    "    return pr_total_dict\n",
    "\n",
    "\n",
    "def get_labels_pr_total(train_data):\n",
    "    \n",
    "    labels = get_labels(train_data)\n",
    "    \n",
    "    for label, _ in train_data:\n",
    "        labels[label] += 1\n",
    "        \n",
    "    total_sum = sum(labels.values())\n",
    "    \n",
    "    for label in labels:\n",
    "        labels[label] /= total_sum\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c1ef2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_row(train_data, row, word_dict, words_no,  labels_dict, pr_label, pr_total_dict, check=False):\n",
    "    \n",
    "    the_label, content = row\n",
    "    new_content = []\n",
    "    i = 0\n",
    "    [new_content.append(x) for x in content if x not in new_content]\n",
    "    for word in new_content:        \n",
    "        pr_total_dict = get_label_pr_for_word(train_data, word, words_no, word_dict, labels_dict, pr_label, pr_total_dict)\n",
    "        #print(pr_total_dict)\n",
    "        \n",
    "    if check:\n",
    "        return max(pr_total_dict, key=pr_total_dict.get) == the_label\n",
    "        \n",
    "    return max(pr_total_dict, key=pr_total_dict.get)\n",
    "\n",
    "\n",
    "def test(train_data, test_data, words_no, word_labels_dict, labels, pr_label):\n",
    "    \n",
    "    probabilities_zero = {}\n",
    "    for label in labels:\n",
    "        probabilities_zero[label] = 0\n",
    "    \n",
    "    output = []\n",
    "    for i in range(len(test_data)):\n",
    "        if i % 10 == 0:\n",
    "            print(i+1, '/', len(test_data))\n",
    "        output.append(test_row(train_data, test_data[i], word_labels_dict, words_no, labels, pr_label, probabilities_zero))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "070214b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessed_train_text + preprocessed_test_text\n",
    "labels = get_labels(data)\n",
    "    \n",
    "word_labels_dict, words_no = get_labels_of_words(preprocessed_train_text, list(labels.keys()))\n",
    "pr_label = get_labels_pr_total(preprocessed_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d8e8a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 802\n",
      "11 / 802\n",
      "21 / 802\n",
      "31 / 802\n",
      "41 / 802\n",
      "51 / 802\n",
      "61 / 802\n",
      "71 / 802\n",
      "81 / 802\n",
      "91 / 802\n",
      "101 / 802\n",
      "111 / 802\n",
      "121 / 802\n",
      "131 / 802\n",
      "141 / 802\n",
      "151 / 802\n",
      "161 / 802\n",
      "171 / 802\n",
      "181 / 802\n",
      "191 / 802\n",
      "201 / 802\n",
      "211 / 802\n",
      "221 / 802\n",
      "231 / 802\n",
      "241 / 802\n",
      "251 / 802\n",
      "261 / 802\n",
      "271 / 802\n",
      "281 / 802\n",
      "291 / 802\n",
      "301 / 802\n",
      "311 / 802\n",
      "321 / 802\n",
      "331 / 802\n",
      "341 / 802\n",
      "351 / 802\n",
      "361 / 802\n",
      "371 / 802\n",
      "381 / 802\n",
      "391 / 802\n",
      "401 / 802\n",
      "411 / 802\n",
      "421 / 802\n",
      "431 / 802\n",
      "441 / 802\n",
      "451 / 802\n",
      "461 / 802\n",
      "471 / 802\n",
      "481 / 802\n",
      "491 / 802\n",
      "501 / 802\n",
      "511 / 802\n",
      "521 / 802\n",
      "531 / 802\n",
      "541 / 802\n",
      "551 / 802\n",
      "561 / 802\n",
      "571 / 802\n",
      "581 / 802\n",
      "591 / 802\n",
      "601 / 802\n",
      "611 / 802\n",
      "621 / 802\n",
      "631 / 802\n",
      "641 / 802\n",
      "651 / 802\n",
      "661 / 802\n",
      "671 / 802\n",
      "681 / 802\n",
      "691 / 802\n",
      "701 / 802\n",
      "711 / 802\n",
      "721 / 802\n",
      "731 / 802\n",
      "741 / 802\n",
      "751 / 802\n",
      "761 / 802\n",
      "771 / 802\n",
      "781 / 802\n",
      "791 / 802\n",
      "801 / 802\n"
     ]
    }
   ],
   "source": [
    "output = test(preprocessed_train_text, preprocessed_test_text, words_no, word_labels_dict, labels, pr_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861d63f",
   "metadata": {},
   "source": [
    "### PART 3 - Accuracy Test\n",
    "\n",
    "##### The problem with only considering Precision and Recall \n",
    "\n",
    "Recall: Within everything that actually is positive, how many did the model succeed to find:\n",
    "\n",
    "    A model with high recall succeeds well in finding all the positive cases in the data, even though they may also wrongly identify some negative cases as positive cases.\n",
    "    A model with low recall is not able to find all (or a large part) of the positive cases in the data.\n",
    "    \n",
    "Precision: Within everything that has been predicted as a positive, precision counts the percentage that is correct:\n",
    "\n",
    "    A not precise model may find a lot of the positives, but its selection method is noisy: it also wrongly detects many positives that aren’t actually positives.\n",
    "    A precise model is very “pure”: maybe it does not find all the positives, but the ones that the model does class as positive are very likely to be correct.\n",
    "    \n",
    "    \n",
    "A high recall by itself is not a good measure of how well our model works, because a high recall value only means the model tends to identify the positive values very well. This does not explain anything on model's performance with negative data and therefore, is an incomplete measurement. For example, a model can simply return positive for any given input. In this case since all positive values are correctly detected, the recall value is equal to 1, even though the model works poorly.\n",
    "\n",
    "In the case for precision, the measurement is also incomplete. For instance, a model can only be capable of classifying simple inputs (e.g. the ones that were seen most while training) as positive value and miss a lot of positive samples due to inflexibility. In this case the precision is rather high which is not a good reflection on how the model is performing.\n",
    "\n",
    "\n",
    "##### F1-Score\n",
    "\n",
    "The F1 score is the \"harmonic mean\" of the precision and recall; Where the harmonic mean H of the positive real numbers ${\\displaystyle x_{1},x_{2},\\ldots ,x_{n}}$ is defined to be:\n",
    "\n",
    "${\\displaystyle H={\\frac {n}{{\\frac {1}{x_{1}}}+{\\frac {1}{x_{2}}}+\\cdots +{\\frac {1}{x_{n}}}}}={\\frac {n}{\\sum \\limits _{i=1}^{n}{\\frac {1}{x_{i}}}}}=\\left({\\frac {\\sum \\limits _{i=1}^{n}x_{i}^{-1}}{n}}\\right)^{-1}.}$\n",
    "\n",
    "The harmonic mean emphasizes the lowest value, so if one of the parameters is small, the second one is no longer influential.\n",
    "\n",
    "Using this formula allows us to have a metric that is not sensitive to extremely large values, but, on the other hand, not all outliers are ignored in it and extremely low values have a significant influence on the result. Such a function is a perfect choice for the scoring metric of a classifier because useless classifiers get a meager score. To sum up, the characteristic of the metric allows us to compare the performance of two classifiers using just one metric and still be sure that the classifiers are not making some horrible mistakes that are unnoticed by the code which scores their output.\n",
    "\n",
    "\n",
    "##### Multi-Class Metrics\n",
    "\n",
    "We used f1-score in classifiers to have a single metric repressenting the whole model. Now with multiple classes at hand, many f1-scores are generated and again the comparison of two non-binary classifiers is rather hard. Multiclass metrics are therefore used to create this single metric as a (relatively good) repressentative of the models.\n",
    "\n",
    "The steps taken for calculating this metric are:\n",
    "\n",
    "    -calculating precision and recall for each clas\n",
    "    -calculating f1-score for each class\n",
    "    -combining the f1-scores\n",
    "    \n",
    "The last step can be taken in many ways:\n",
    "\n",
    "    1.Macro-F1: It is computed as a simple arithmetic mean of our per-class F1-scores\n",
    "    2.Weighted-F1: In this, we weight the F1-score of each class by the number of samples from that class.\n",
    "    3.micro-F1: We consider all the samples and (precision, recall, f1, and accuracy are equal in this method)\n",
    "    \n",
    "    \n",
    "**NOTE: The f1-score is calculated with the precision and recall generated through the aforementioned approaches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "98831eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARi0lEQVR4nO3dfZBk1V3G8e8DC4TXBGRB3CUs0TUIEpMwIjFVKctE2ZiUiwZ0TQEbi2Qr1BIxvkTQaKKmTKqMVoIlKCbCYlIikhdWBQ1ufJcCZ8kLLhtkAwILBCZ/mKCWGMjPP+5ZaWaHnYHM9szO+X6qurr79Dm3z709/fTp0/feSVUhSerDfgvdAUnS+Bj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdWbbQHZjN0UcfXatWrVrobkjSPmXr1q1frqrl08sXfeivWrWKycnJhe6GJO1Tktw3U7nTO5LUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOLPqDs74Ryfwty/81I2kpcKQvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHZlT6Cd5e5JtSf41yR8neV6So5LcnOTudn3kSP1Lk+xIcleSM0fKT0tyR3vssmQ+/7eVJGk2s4Z+khXATwETVfWdwP7AOuASYEtVrQa2tPskObk9fgqwBrg8yf5tcVcAG4DV7bJmXtdGkrRHc53eWQYcnGQZcAjwELAW2NQe3wSc1W6vBa6tqser6l5gB3B6kuOAI6rqlqoq4JqRNpKkMZg19KvqQeD9wP3Aw8BXqupTwLFV9XCr8zBwTGuyAnhgZBE7W9mKdnt6uSRpTOYyvXMkw+j9ROBbgEOTnLunJjOU1R7KZ3rODUkmk0xOTU3N1kVJ0hzNZXrnNcC9VTVVVV8DPg58L/BIm7KhXT/a6u8Ejh9pv5JhOmhnuz29fDdVdWVVTVTVxPLly5/N+kiS9mAuoX8/cEaSQ9reNq8GtgObgfWtznrghnZ7M7AuyUFJTmT4wfa2NgX0WJIz2nLOH2kjSRqDZbNVqKpbk1wP3A48AXwGuBI4DLguyQUMHwzntPrbklwH3Nnqb6yqJ9viLgSuBg4GbmoXSdKYZNiRZvGamJioycnJ59R2Po8CWOSbSZKeJsnWqpqYXu4RuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR2ZU+gneUGS65N8Icn2JK9IclSSm5Pc3a6PHKl/aZIdSe5KcuZI+WlJ7miPXZYke2OlJEkzm+tI/4PAX1bVScB3AduBS4AtVbUa2NLuk+RkYB1wCrAGuDzJ/m05VwAbgNXtsmae1kOSNAezhn6SI4BXAR8GqKr/rar/ANYCm1q1TcBZ7fZa4Nqqeryq7gV2AKcnOQ44oqpuqaoCrhlpI0kag7mM9F8ETAFXJflMkg8lORQ4tqoeBmjXx7T6K4AHRtrvbGUr2u3p5ZKkMZlL6C8DXg5cUVUvA/6LNpXzDGaap689lO++gGRDkskkk1NTU3PooiRpLuYS+juBnVV1a7t/PcOHwCNtyoZ2/ehI/eNH2q8EHmrlK2co301VXVlVE1U1sXz58rmuiyRpFrOGflV9CXggyYtb0auBO4HNwPpWth64od3eDKxLclCSExl+sL2tTQE9luSMttfO+SNtJEljsGyO9d4GfDTJgcA9wE8yfGBcl+QC4H7gHICq2pbkOoYPhieAjVX1ZFvOhcDVwMHATe0iSRqTDDvSLF4TExM1OTn5nNrO51EAi3wzSdLTJNlaVRPTyz0iV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZM6hn2T/JJ9J8uft/lFJbk5yd7s+cqTupUl2JLkryZkj5acluaM9dlmSzO/qSJL25NmM9C8Gto/cvwTYUlWrgS3tPklOBtYBpwBrgMuT7N/aXAFsAFa3y5pvqPeSpGdlTqGfZCXwOuBDI8VrgU3t9ibgrJHya6vq8aq6F9gBnJ7kOOCIqrqlqgq4ZqSNJGkM5jrS/wDwDuDrI2XHVtXDAO36mFa+AnhgpN7OVrai3Z5eLkkak1lDP8nrgUerausclznTPH3toXym59yQZDLJ5NTU1ByfVpI0m7mM9F8J/HCSfweuBb4/yUeAR9qUDe360VZ/J3D8SPuVwEOtfOUM5bupqiuraqKqJpYvX/4sVkeStCezhn5VXVpVK6tqFcMPtJ+uqnOBzcD6Vm09cEO7vRlYl+SgJCcy/GB7W5sCeizJGW2vnfNH2kiSxmDZN9D2fcB1SS4A7gfOAaiqbUmuA+4EngA2VtWTrc2FwNXAwcBN7aIlaD53xq0ZJwElPRepRf6OmpiYqMnJyefU1uBZOG57aWEl2VpVE9PLPSJXkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXkGzmfvqRFyNNaa08c6UtSRwx9SeqIoS9JHTH0Jakj/pArSfNkX/gR3ZG+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTW0E9yfJK/SbI9ybYkF7fyo5LcnOTudn3kSJtLk+xIcleSM0fKT0tyR3vssmQ+/8+MJGk2cxnpPwH8bFV9B3AGsDHJycAlwJaqWg1safdpj60DTgHWAJcn2b8t6wpgA7C6XdbM47pIkmYxa+hX1cNVdXu7/RiwHVgBrAU2tWqbgLPa7bXAtVX1eFXdC+wATk9yHHBEVd1SVQVcM9JGkjQGz2pOP8kq4GXArcCxVfUwDB8MwDGt2grggZFmO1vZinZ7erkkaUzmHPpJDgM+Bvx0VX11T1VnKKs9lM/0XBuSTCaZnJqammsXJUmzmFPoJzmAIfA/WlUfb8WPtCkb2vWjrXwncPxI85XAQ6185Qzlu6mqK6tqoqomli9fPtd1kSTNYi577wT4MLC9qn575KHNwPp2ez1ww0j5uiQHJTmR4Qfb29oU0GNJzmjLPH+kjSRpDJbNoc4rgfOAO5J8tpX9IvA+4LokFwD3A+cAVNW2JNcBdzLs+bOxqp5s7S4ErgYOBm5qF0nSmGTYkWbxmpiYqMnJyefUdj6PAljkm2nRcdsvHLf9wllM2z7J1qqamF7uEbmS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSNjD/0ka5LclWRHkkvG/fyS1LOxhn6S/YHfBV4LnAz8RJKTx9kHSerZuEf6pwM7quqeqvpf4Fpg7Zj7IEndGnforwAeGLm/s5VJksZg2ZifLzOU1W6Vkg3Ahnb3P5PctRf7dDTw5dkqZaaeaz7Muv3d9nuN237hjGPbnzBT4bhDfydw/Mj9lcBD0ytV1ZXAlePoUJLJqpoYx3Npd27/heO2XzgLue3HPb3zL8DqJCcmORBYB2wecx8kqVtjHelX1RNJLgL+Ctgf+MOq2jbOPkhSz8Y9vUNV3QjcOO7n3YOxTCPpGbn9F47bfuEs2LZP1W6/o0qSlqglfxqGJCctdB8kabFYkqGf5MAk65J8AnjrQvdHkhaLJRf6Sb4T+DjwTcBfA9+zsD2S9h1twPTGJH+f5IiF7s9SluRvk3zbMzz2piTv2RvPu+RCH7gH2A5czHBMwE8sbHeWpiSrkrxlofuh+ZFkvyTvBrYxDJTeXFVfXdheaW9YiqH/GmACOLWqLqmqf59rwyRnJzlrr/VsCWnb9RVJzt1TvSTPa8dk7KnOwUk2zlC+LsmdST6X5Mxpj31XkgOSHJ3ktc9lHZaiJGe03aKfrQngx4CXV9XFVfVv89w1LRJLMfT/DjgGeNlzaHsWcPb8dmdJ+w3g4iSnJrk9yS1JjptW52zgnUkOSbI9mfHg8hcwfDOb7hLg7Qwn5TsKoC3noKr6XFV9DfgK8PtJluLf8nNxEfCtSZY/y3afBf4LeNX8d0mLyT7/Rsng8F33q+orDCOWP0oy55O5JTmwqs4Fzts1Mk3ya0lOm1bvBUk+nuSeJB+ZbRS7FCXZdXzHS4D/BN4CfAy4hiF0Rn2Z4XQbyxjC/ZSR5RzeRumfpO23nOQHk7ykVXkb8EvAHwB/38quYvg2B0AL/ing2YbcktM+DM+tqrcDX21lFyZ5/UidQ3a9fqNz9u2stz8KfGCm05235fxskgtHlvPCvbxKS1KS9yR500I9/z4f+sAPAB8cLWhH+V4BbARI8ptJ7ksy02hy13n+72ij0JOBT7eHXgQcNq369/FUeP0VfYbNWUkeYBiJXwx8FDgP+FWGb1mj1gGTbX74rcBVSR5Och/DaTneCPxyVb2/1f9p2kGDVfUPVfUq4G6GQAI4kpHzNbUP3eOA/5j3tdz33JLk+UkOBb7YylYw7NSwy88A5yf5doYP2/9XVQ8A7wJ+DiDJ8W0POKrqiqr6raq6olX/duDDe29VloYkn01yRJJD23sGhhNP1rR60wePy4Cv7Y0+LYXQfwI4NcnqNup/XhvZnAt8MclRDCPRlwMXtY3/wiSX7VpAVT0J3MdTvwecnOT5wAuBLyU5KMnbWvWbgNuBrcDhVfXguFZ0saiq66vq+Ko6vao+X1W3VtVJwJ8ybPP9kpyS5GqGD9GrWrsbquq7q+q4qjqhqk6qqvOq6lMji78ReG+Sn0zyM0k+BnwH8Mft8duBN7X5/IOA9wOfqKrHx7T6i0L7O/7otOJJhm+5E8A3J3kR7W94pM6ub15fB05I8tL2eh2Q5NUMH8y7PjCOAE4aHdG3b2c/CFwO/MXeWLd9VZJjk3x2WvFtwI8DpzG8JicCqxhOPrmr3aE8Nejc5SSe/rrNn6ra5y8Mp2H+l7Yh/41hmmHNyOMfAh4E/odh5LMRuGTaMrYB9wI7gF8HHmE4NxAM//xl87T6xwJTC73ui+ECPB/4+bbNjm3b8FPABcCBz9Bm0x6Wd3p7jd4IrJ722CEMgfMF4C6G3xVmfI6lfAFeB/zetLIbgfsZ/mfFrzB8I7oRWNYe3w/YAvxQu3828I/tffNF4E+AN9CO1G91NjLsDfcQw8DoC8BHgNcu9DZYbBfgR4DfmVb2FzO8Jn/GcO6xvwW+rb1/HmTY2/BA4JzW5lv2Rj+7OQ1DkpXA5xnOY30RcCpwIcNGfifDG+Glz9D2MOCfGf7T15eAFwNrgMuqquuvuEn+jmGb/hPwnqq6f4G71IUkP8wwKv9RhlH7mxl+/1hdVf89re4yhh0b3tXqrq1e3vhjlOSHGHY8OIthauYChmzZ7TWZoe164B0MeXQL8N6q2r5X+rnUX/v2lemlDFMMn6yqd7epm98HvpvhE/fTwC9U1dQelnM4w4t5KMMc8y2zvZDS3pLkAOB3GKYkD2D4pvuOqrpnWr0TgJt5aoR+fVV9fczd7UL7cP0Aw4DwGV+ThbakQz/JG4D3MXy1+qOqumqBuyRJC2pJh74k6emWwt47kqQ5MvQlqSOGviR1xNCXpI4Y+pLUEUNfkjryf9r1uozEvcpmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    \n",
    "    d = dict(sorted(word_labels_dict.items(), key=lambda item: item[1][i], reverse=True)[0:4])\n",
    "    x = list(d.keys())\n",
    "    y = [d[label][i] for label in x]\n",
    "    plt.bar(x, y, color ='blue', width = 0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0c495cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = o\n",
    "\n",
    "labels = get_labels(preprocessed_train_text)\n",
    "tp_dict = get_labels(preprocessed_train_text)\n",
    "fp_dict = get_labels(preprocessed_train_text)\n",
    "fn_dict = get_labels(preprocessed_train_text)\n",
    "precision_dict = get_labels(preprocessed_train_text)\n",
    "recall_dict = get_labels(preprocessed_train_text)\n",
    "f1_dict = get_labels(preprocessed_train_text)\n",
    "\n",
    "t = 0\n",
    "f = 0\n",
    "for i in range(len(preprocessed_test_text)):\n",
    "    \n",
    "    if preprocessed_test_text[i][0] == output[i]:\n",
    "        t += 1\n",
    "        tp_dict[output[i]] += 1\n",
    "    else:\n",
    "        f += 1\n",
    "        fp_dict[output[i]] += 1\n",
    "        fn_dict[preprocessed_test_text[i][0]] += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "eae1b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    \n",
    "    if (tp_dict[label] + fp_dict[label]) != 0:\n",
    "        precision_dict[label] = tp_dict[label] / (tp_dict[label] + fp_dict[label])\n",
    "        \n",
    "    if (fn_dict[label] + tp_dict[label]) != 0:\n",
    "        recall_dict[label] = tp_dict[label] / (fn_dict[label] + tp_dict[label])\n",
    "        \n",
    "    if (recall_dict[label] + precision_dict[label]) != 0:\n",
    "        f1_dict[label] = 2 * recall_dict[label] * precision_dict[label] / (recall_dict[label] + precision_dict[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558f290",
   "metadata": {},
   "source": [
    "#### Results with Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8f29e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.22069825436408977\n",
      "MACRO-F1: 0.23390774609268444\n",
      "Weighed-F1: 0.23390774609268444\n",
      "MiCRO-F1: 0.22069825436408977\n"
     ]
    }
   ],
   "source": [
    "mean_precision = mean(precision_dict.values())\n",
    "mean_recall = mean(recall_dict.values())\n",
    "macro_f1 = 2 * mean_precision * mean_recall / (mean_precision + mean_recall)\n",
    "\n",
    "wm_precision = 0\n",
    "wm_recall = 0\n",
    "\n",
    "for label in labels:\n",
    "    wm_precision += pr_label[label] * precision_dict[label]\n",
    "    wm_recall += pr_label[label] * recall_dict[label]\n",
    "\n",
    "weighed_f1 = 2 * wm_recall * wm_precision / (wm_recall + wm_precision) \n",
    "\n",
    "accuracy = t / (t + f)\n",
    "\n",
    "\n",
    "print('ACCURACY:', accuracy)\n",
    "print('MACRO-F1:', macro_f1)\n",
    "print('Weighed-F1:', weighed_f1)\n",
    "print('MiCRO-F1:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7075fb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.210458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.210458\n",
       "1  علم تکنولوژی  0.483871\n",
       "2  سلامت زیبایی  0.166667\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(precision_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4208d904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.964072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.054152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.964072\n",
       "1  علم تکنولوژی  0.054152\n",
       "2  سلامت زیبایی  0.006211\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(recall_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "faf2e642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.345494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.097403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.345494\n",
       "1  علم تکنولوژی  0.097403\n",
       "2  سلامت زیبایی  0.011976\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(f1_dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051352f0",
   "metadata": {},
   "source": [
    "#### Results without smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2c6cc550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 0.22069825436408977\n",
      "MACRO-F1: 0.23390774609268444\n",
      "Weighed-F1: 0.23390774609268444\n",
      "MiCRO-F1: 0.22069825436408977\n"
     ]
    }
   ],
   "source": [
    "mean_precision = mean(precision_dict.values())\n",
    "mean_recall = mean(recall_dict.values())\n",
    "macro_f1 = 2 * mean_precision * mean_recall / (mean_precision + mean_recall)\n",
    "\n",
    "wm_precision = 0\n",
    "wm_recall = 0\n",
    "\n",
    "for label in labels:\n",
    "    wm_precision += pr_label[label] * precision_dict[label]\n",
    "    wm_recall += pr_label[label] * recall_dict[label]\n",
    "\n",
    "weighed_f1 = 2 * wm_recall * wm_precision / (wm_recall + wm_precision) \n",
    "\n",
    "accuracy = t / (t + f)\n",
    "\n",
    "\n",
    "print('ACCURACY:', accuracy)\n",
    "print('MACRO-F1:', macro_f1)\n",
    "print('Weighed-F1:', weighed_f1)\n",
    "print('MiCRO-F1:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d0895c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.210458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.210458\n",
       "1  علم تکنولوژی  0.483871\n",
       "2  سلامت زیبایی  0.166667\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(precision_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "197629ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.964072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.054152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.006211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.964072\n",
       "1  علم تکنولوژی  0.054152\n",
       "2  سلامت زیبایی  0.006211\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(recall_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "35942f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>هنر سینما</td>\n",
       "      <td>0.345494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>علم تکنولوژی</td>\n",
       "      <td>0.097403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>سلامت زیبایی</td>\n",
       "      <td>0.011976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>بازی ویدیویی</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0     هنر سینما  0.345494\n",
       "1  علم تکنولوژی  0.097403\n",
       "2  سلامت زیبایی  0.011976\n",
       "3  بازی ویدیویی  0.000000"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(f1_dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4eead",
   "metadata": {},
   "source": [
    "####  Conclusion\n",
    "\n",
    "Though many approaching on various levels have been tried, our model is incapable of predicting the labels and is performing poorly. This is most probably due to a mistake in calculating the bayas theorm's formula. Different preprocessing methods have been tested. Amongst them was using lemmatizing, stemming, fixing the spaces between words, normalzing the values, .... In the end, not using the lemmatizing and stemming parts proved a small improvement in the model. For filtering the stopwords, a combination of the stopwords imported from Hazm and the 13 most frequent words in the train data had the best results.\n",
    "\n",
    "Unfortunately, even though the most frequent words of each label seem to be logically detected, the overall model does not operate as expected. Still, we see a slight improvement with the use of additive smoothing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
